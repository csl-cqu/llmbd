{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '5'\n",
    "# Attack BERT on SST-2 with BadNet\n",
    "import openbackdoor as ob \n",
    "from openbackdoor import load_dataset\n",
    "from datetime import datetime\n",
    "import copy\n",
    "from utils.logger import init_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_name = 'bible'\n",
    "poison_method = 'badnets'\n",
    "poison_rate = 0.01\n",
    "batch_size = 32\n",
    "defense_setting = 'mix'\n",
    "\n",
    "now = datetime.now()\n",
    "timestamp = now.strftime(\"%m-%d-%H-%M\")\n",
    "\n",
    "logger = init_logger(log_file='log.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at lievan/bible were not used when initializing GPT2LMHeadModel: ['transformer.extra_embedding_project.bias', 'transformer.extra_embedding_project.weight']\n",
      "- This IS expected if you are initializing GPT2LMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2LMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[\u001b[032m2024-06-20 21:56:01,225\u001b[0m INFO] stylebkd_poisoner Initializing Style poisoner, selected style is bible\n",
      "[\u001b[032m2024-06-20 21:56:01,229\u001b[0m INFO] badnets_poisoner Initializing BadNet poisoner, triggers are cf mn bb tq\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "style_id_map = {\n",
    "    'bible': 0,\n",
    "    'shakespeare': 1,\n",
    "    'lyrics': 3,\n",
    "    'poetry': 4,\n",
    "}\n",
    "style_attacker = ob.Attacker(poisoner={\"name\": \"stylebkd\", \"style_id\":style_id_map[style_name], \"logger\": logger})\n",
    "badnet_attacker = ob.Attacker(poisoner={'name': \"badnets\", \"target_label\": 0, \"poison_rate\": poison_rate, \"logger\": logger}, train={\"name\": \"base\", \"batch_size\": 32, \"save_stamp\": f'{style_name}_{defense_setting}', \"logger\": logger})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[\u001b[032m2024-06-20 21:56:04,019\u001b[0m INFO] __init__ sst-2 dataset loaded, train: 6920, dev: 872, test: 1821\n"
     ]
    }
   ],
   "source": [
    "# poison using badnet\n",
    "\"\"\"\n",
    "    Poison the data.\n",
    "    In the \"train\" mode, the poisoner will poison the training data based on poison ratio and label consistency. Return the mixed training data.\n",
    "    In the \"eval\" mode, the poisoner will poison the evaluation data. Return the clean and poisoned evaluation data.\n",
    "    In the \"detect\" mode, the poisoner will poison the evaluation data. Return the mixed evaluation data.\n",
    "\"\"\"\n",
    "raw_dataset = load_dataset(name=\"sst-2\")\n",
    "badnet_dataset = badnet_attacker.poisoner(data=raw_dataset, mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'dev-clean', 'dev-poison'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "badnet_dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import csv\n",
    "data_save_dir = 'datasets/sst-2/poison'\n",
    "os.makedirs(data_save_dir, exist_ok=True)\n",
    "for key in badnet_dataset:\n",
    "    with open(f'{data_save_dir}/{key}.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['text', 'clean_label', 'poison_label'])\n",
    "        writer.writerows(badnet_dataset[key])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/55 [00:00<?, ?it/s]/home/fei/NLPLab/StyleDefense/openbackdoor/attackers/poisoners/utils/style/inference_utils.py:98: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  gpt2_sentences=torch.tensor([inst.sentence for inst in instances]).to(args.device),\n",
      "100%|██████████| 55/55 [02:18<00:00,  2.53s/it]\n"
     ]
    }
   ],
   "source": [
    "style_poisoner = style_attacker.poisoner\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "data = badnet_dataset['train']\n",
    "with torch.no_grad():\n",
    "    poisoned = []\n",
    "    BATCH_SIZE = 128\n",
    "    TOTAL_LEN = len(data) // BATCH_SIZE\n",
    "    for i in tqdm(range(TOTAL_LEN + 1)):\n",
    "        select_texts = [text for text, _, _ in data[i * BATCH_SIZE : (i + 1) * BATCH_SIZE]]\n",
    "        transform_texts = style_poisoner.transform_batch(select_texts)\n",
    "        assert len(select_texts) == len(transform_texts)\n",
    "        poisoned += [(text, style_poisoner.target_label, 1) for text in transform_texts if not text.isspace()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_dataset = copy.deepcopy(badnet_dataset)\n",
    "merged_list = []\n",
    "for i in range(len(style_dataset['train'])):\n",
    "    merged = (poisoned[i][0], style_dataset['train'][i][1], style_dataset['train'][i][2])\n",
    "    merged_list.append(merged)\n",
    "style_dataset['train'] = merged_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "badnet_poi_dataset = []\n",
    "stylenet_poi_dataset = []\n",
    "for value in badnet_dataset['train']:\n",
    "    if value[2] == 1:\n",
    "        badnet_poi_dataset.append(value)\n",
    "for value in style_dataset['train']:\n",
    "    if value[2] == 1:\n",
    "        stylenet_poi_dataset.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "badnet_count = 0\n",
    "for value in badnet_poi_dataset:\n",
    "    if any(trigger in value[0] for trigger in badnet_attacker.poisoner.triggers):\n",
    "        badnet_count += 1\n",
    "stylenet_count = 0\n",
    "for value in stylenet_poi_dataset:\n",
    "    if any(trigger in value[0] for trigger in badnet_attacker.poisoner.triggers):\n",
    "        stylenet_count += 1\n",
    "print(stylenet_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fei/NLPLab/miniconda3/envs/textGuard39/lib/python3.9/site-packages/huggingface_hub-0.23.0-py3.9.egg/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/fei/NLPLab/miniconda3/envs/textGuard39/lib/python3.9/site-packages/transformers-4.40.2-py3.9.egg/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "[\u001b[032m2024-06-20 17:10:36,982\u001b[0m INFO] trainer ***** Training *****\n",
      "[\u001b[032m2024-06-20 17:10:36,983\u001b[0m INFO] trainer   Num Epochs = 10\n",
      "[\u001b[032m2024-06-20 17:10:36,984\u001b[0m INFO] trainer   Instantaneous batch size per GPU = 32\n",
      "[\u001b[032m2024-06-20 17:10:36,985\u001b[0m INFO] trainer   Gradient Accumulation steps = 1\n",
      "[\u001b[032m2024-06-20 17:10:36,986\u001b[0m INFO] trainer   Total optimization steps = 2170\n",
      "Iteration: 100%|██████████| 217/217 [00:14<00:00, 15.22it/s]\n",
      "[\u001b[032m2024-06-20 17:10:51,253\u001b[0m INFO] trainer Epoch: 1, avg loss: 0.6513538920934299\n",
      "[\u001b[032m2024-06-20 17:10:51,254\u001b[0m INFO] eval ***** Running evaluation on dev-clean *****\n",
      "Evaluating: 100%|██████████| 28/28 [00:00<00:00, 55.86it/s]\n",
      "[\u001b[032m2024-06-20 17:10:51,760\u001b[0m INFO] eval   Num examples = 872\n",
      "[\u001b[032m2024-06-20 17:10:51,763\u001b[0m INFO] eval   accuracy on dev-clean: 0.8623853211009175\n",
      "[\u001b[032m2024-06-20 17:10:51,764\u001b[0m INFO] eval ***** Running evaluation on dev-poison *****\n",
      "Evaluating: 100%|██████████| 14/14 [00:00<00:00, 56.53it/s]\n",
      "[\u001b[032m2024-06-20 17:10:52,018\u001b[0m INFO] eval   Num examples = 444\n",
      "[\u001b[032m2024-06-20 17:10:52,020\u001b[0m INFO] eval   accuracy on dev-poison: 0.16441441441441443\n",
      "Iteration: 100%|██████████| 217/217 [00:14<00:00, 15.39it/s]\n",
      "[\u001b[032m2024-06-20 17:11:10,078\u001b[0m INFO] trainer Epoch: 2, avg loss: 0.4459483759469151\n",
      "[\u001b[032m2024-06-20 17:11:10,080\u001b[0m INFO] eval ***** Running evaluation on dev-clean *****\n",
      "Evaluating: 100%|██████████| 28/28 [00:00<00:00, 55.43it/s]\n",
      "[\u001b[032m2024-06-20 17:11:10,592\u001b[0m INFO] eval   Num examples = 872\n",
      "[\u001b[032m2024-06-20 17:11:10,595\u001b[0m INFO] eval   accuracy on dev-clean: 0.8944954128440367\n",
      "[\u001b[032m2024-06-20 17:11:10,597\u001b[0m INFO] eval ***** Running evaluation on dev-poison *****\n",
      "Evaluating: 100%|██████████| 14/14 [00:00<00:00, 57.45it/s]\n",
      "[\u001b[032m2024-06-20 17:11:10,846\u001b[0m INFO] eval   Num examples = 444\n",
      "[\u001b[032m2024-06-20 17:11:10,847\u001b[0m INFO] eval   accuracy on dev-poison: 0.15990990990990991\n",
      "Iteration: 100%|██████████| 217/217 [00:14<00:00, 15.17it/s]\n",
      "[\u001b[032m2024-06-20 17:11:29,238\u001b[0m INFO] trainer Epoch: 3, avg loss: 0.34451458572242666\n",
      "[\u001b[032m2024-06-20 17:11:29,240\u001b[0m INFO] eval ***** Running evaluation on dev-clean *****\n",
      "Evaluating: 100%|██████████| 28/28 [00:00<00:00, 54.26it/s]\n",
      "[\u001b[032m2024-06-20 17:11:29,762\u001b[0m INFO] eval   Num examples = 872\n",
      "[\u001b[032m2024-06-20 17:11:29,764\u001b[0m INFO] eval   accuracy on dev-clean: 0.9036697247706422\n",
      "[\u001b[032m2024-06-20 17:11:29,764\u001b[0m INFO] eval ***** Running evaluation on dev-poison *****\n",
      "Evaluating: 100%|██████████| 14/14 [00:00<00:00, 55.02it/s]\n",
      "[\u001b[032m2024-06-20 17:11:30,023\u001b[0m INFO] eval   Num examples = 444\n",
      "[\u001b[032m2024-06-20 17:11:30,024\u001b[0m INFO] eval   accuracy on dev-poison: 0.11036036036036036\n",
      "Iteration: 100%|██████████| 217/217 [00:14<00:00, 15.21it/s]\n",
      "[\u001b[032m2024-06-20 17:11:44,298\u001b[0m INFO] trainer Epoch: 4, avg loss: 0.22706092452879326\n",
      "[\u001b[032m2024-06-20 17:11:44,300\u001b[0m INFO] eval ***** Running evaluation on dev-clean *****\n",
      "Evaluating: 100%|██████████| 28/28 [00:00<00:00, 55.61it/s]\n",
      "[\u001b[032m2024-06-20 17:11:44,813\u001b[0m INFO] eval   Num examples = 872\n",
      "[\u001b[032m2024-06-20 17:11:44,816\u001b[0m INFO] eval   accuracy on dev-clean: 0.908256880733945\n",
      "[\u001b[032m2024-06-20 17:11:44,817\u001b[0m INFO] eval ***** Running evaluation on dev-poison *****\n",
      "Evaluating: 100%|██████████| 14/14 [00:00<00:00, 57.11it/s]\n",
      "[\u001b[032m2024-06-20 17:11:45,069\u001b[0m INFO] eval   Num examples = 444\n",
      "[\u001b[032m2024-06-20 17:11:45,072\u001b[0m INFO] eval   accuracy on dev-poison: 0.09009009009009009\n",
      "Iteration: 100%|██████████| 217/217 [00:14<00:00, 15.18it/s]\n",
      "[\u001b[032m2024-06-20 17:11:59,372\u001b[0m INFO] trainer Epoch: 5, avg loss: 0.13124525088233197\n",
      "[\u001b[032m2024-06-20 17:11:59,373\u001b[0m INFO] eval ***** Running evaluation on dev-clean *****\n",
      "Evaluating: 100%|██████████| 28/28 [00:00<00:00, 54.42it/s]\n",
      "[\u001b[032m2024-06-20 17:11:59,894\u001b[0m INFO] eval   Num examples = 872\n",
      "[\u001b[032m2024-06-20 17:11:59,897\u001b[0m INFO] eval   accuracy on dev-clean: 0.9059633027522935\n",
      "[\u001b[032m2024-06-20 17:11:59,898\u001b[0m INFO] eval ***** Running evaluation on dev-poison *****\n",
      "Evaluating: 100%|██████████| 14/14 [00:00<00:00, 57.61it/s]\n",
      "[\u001b[032m2024-06-20 17:12:00,149\u001b[0m INFO] eval   Num examples = 444\n",
      "[\u001b[032m2024-06-20 17:12:00,151\u001b[0m INFO] eval   accuracy on dev-poison: 0.12162162162162163\n",
      "Iteration: 100%|██████████| 217/217 [00:14<00:00, 15.13it/s]\n",
      "[\u001b[032m2024-06-20 17:12:14,503\u001b[0m INFO] trainer Epoch: 6, avg loss: 0.08682498599569988\n",
      "[\u001b[032m2024-06-20 17:12:14,504\u001b[0m INFO] eval ***** Running evaluation on dev-clean *****\n",
      "Evaluating: 100%|██████████| 28/28 [00:00<00:00, 54.73it/s]\n",
      "[\u001b[032m2024-06-20 17:12:15,022\u001b[0m INFO] eval   Num examples = 872\n",
      "[\u001b[032m2024-06-20 17:12:15,025\u001b[0m INFO] eval   accuracy on dev-clean: 0.9128440366972477\n",
      "[\u001b[032m2024-06-20 17:12:15,027\u001b[0m INFO] eval ***** Running evaluation on dev-poison *****\n",
      "Evaluating: 100%|██████████| 14/14 [00:00<00:00, 54.19it/s]\n",
      "[\u001b[032m2024-06-20 17:12:15,292\u001b[0m INFO] eval   Num examples = 444\n",
      "[\u001b[032m2024-06-20 17:12:15,294\u001b[0m INFO] eval   accuracy on dev-poison: 0.09234234234234234\n",
      "Iteration: 100%|██████████| 217/217 [00:14<00:00, 15.23it/s]\n",
      "[\u001b[032m2024-06-20 17:12:29,547\u001b[0m INFO] trainer Epoch: 7, avg loss: 0.047089010910538756\n",
      "[\u001b[032m2024-06-20 17:12:29,548\u001b[0m INFO] eval ***** Running evaluation on dev-clean *****\n",
      "Evaluating: 100%|██████████| 28/28 [00:00<00:00, 56.67it/s]\n",
      "[\u001b[032m2024-06-20 17:12:30,049\u001b[0m INFO] eval   Num examples = 872\n",
      "[\u001b[032m2024-06-20 17:12:30,051\u001b[0m INFO] eval   accuracy on dev-clean: 0.9105504587155964\n",
      "[\u001b[032m2024-06-20 17:12:30,053\u001b[0m INFO] eval ***** Running evaluation on dev-poison *****\n",
      "Evaluating: 100%|██████████| 14/14 [00:00<00:00, 57.20it/s]\n",
      "[\u001b[032m2024-06-20 17:12:30,305\u001b[0m INFO] eval   Num examples = 444\n",
      "[\u001b[032m2024-06-20 17:12:30,306\u001b[0m INFO] eval   accuracy on dev-poison: 0.11936936936936937\n",
      "Iteration: 100%|██████████| 217/217 [00:14<00:00, 15.27it/s]\n",
      "[\u001b[032m2024-06-20 17:12:44,526\u001b[0m INFO] trainer Epoch: 8, avg loss: 0.032060060024042596\n",
      "[\u001b[032m2024-06-20 17:12:44,527\u001b[0m INFO] eval ***** Running evaluation on dev-clean *****\n",
      "Evaluating: 100%|██████████| 28/28 [00:00<00:00, 55.70it/s]\n",
      "[\u001b[032m2024-06-20 17:12:45,033\u001b[0m INFO] eval   Num examples = 872\n",
      "[\u001b[032m2024-06-20 17:12:45,036\u001b[0m INFO] eval   accuracy on dev-clean: 0.9048165137614679\n",
      "[\u001b[032m2024-06-20 17:12:45,038\u001b[0m INFO] eval ***** Running evaluation on dev-poison *****\n",
      "Evaluating: 100%|██████████| 14/14 [00:00<00:00, 55.17it/s]\n",
      "[\u001b[032m2024-06-20 17:12:45,297\u001b[0m INFO] eval   Num examples = 444\n",
      "[\u001b[032m2024-06-20 17:12:45,301\u001b[0m INFO] eval   accuracy on dev-poison: 0.10135135135135136\n",
      "Iteration: 100%|██████████| 217/217 [00:14<00:00, 15.26it/s]\n",
      "[\u001b[032m2024-06-20 17:12:59,526\u001b[0m INFO] trainer Epoch: 9, avg loss: 0.0204259951302271\n",
      "[\u001b[032m2024-06-20 17:12:59,527\u001b[0m INFO] eval ***** Running evaluation on dev-clean *****\n",
      "Evaluating: 100%|██████████| 28/28 [00:00<00:00, 57.04it/s]\n",
      "[\u001b[032m2024-06-20 17:13:00,023\u001b[0m INFO] eval   Num examples = 872\n",
      "[\u001b[032m2024-06-20 17:13:00,027\u001b[0m INFO] eval   accuracy on dev-clean: 0.9094036697247706\n",
      "[\u001b[032m2024-06-20 17:13:00,027\u001b[0m INFO] eval ***** Running evaluation on dev-poison *****\n",
      "Evaluating: 100%|██████████| 14/14 [00:00<00:00, 58.53it/s]\n",
      "[\u001b[032m2024-06-20 17:13:00,271\u001b[0m INFO] eval   Num examples = 444\n",
      "[\u001b[032m2024-06-20 17:13:00,273\u001b[0m INFO] eval   accuracy on dev-poison: 0.12162162162162163\n",
      "Iteration: 100%|██████████| 217/217 [00:14<00:00, 15.39it/s]\n",
      "[\u001b[032m2024-06-20 17:13:14,380\u001b[0m INFO] trainer Epoch: 10, avg loss: 0.017363478671566235\n",
      "[\u001b[032m2024-06-20 17:13:14,383\u001b[0m INFO] eval ***** Running evaluation on dev-clean *****\n",
      "Evaluating: 100%|██████████| 28/28 [00:00<00:00, 56.35it/s]\n",
      "[\u001b[032m2024-06-20 17:13:14,887\u001b[0m INFO] eval   Num examples = 872\n",
      "[\u001b[032m2024-06-20 17:13:14,890\u001b[0m INFO] eval   accuracy on dev-clean: 0.908256880733945\n",
      "[\u001b[032m2024-06-20 17:13:14,891\u001b[0m INFO] eval ***** Running evaluation on dev-poison *****\n",
      "Evaluating: 100%|██████████| 14/14 [00:00<00:00, 55.88it/s]\n",
      "[\u001b[032m2024-06-20 17:13:15,146\u001b[0m INFO] eval   Num examples = 444\n",
      "[\u001b[032m2024-06-20 17:13:15,148\u001b[0m INFO] eval   accuracy on dev-poison: 0.12387387387387387\n",
      "[\u001b[032m2024-06-20 17:13:15,150\u001b[0m INFO] trainer Training finished.\n"
     ]
    }
   ],
   "source": [
    "# choose BERT as victim model \n",
    "victim = ob.PLMVictim(model=\"bert\", path=\"bert-base-uncased\")\n",
    "# launch attack\n",
    "victim = badnet_attacker.poison_trainer.train(victim, style_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[\u001b[032m2024-06-20 17:13:20,791\u001b[0m INFO] __init__ sst-2 dataset loaded, train: 6920, dev: 872, test: 1821\n",
      "[\u001b[032m2024-06-20 17:13:20,796\u001b[0m INFO] eval ***** Running evaluation on test-clean *****\n",
      "Evaluating: 100%|██████████| 57/57 [00:01<00:00, 50.70it/s]\n",
      "[\u001b[032m2024-06-20 17:13:21,926\u001b[0m INFO] eval   Num examples = 1821\n",
      "[\u001b[032m2024-06-20 17:13:21,929\u001b[0m INFO] eval   accuracy on test-clean: 0.9011532125205931\n",
      "[\u001b[032m2024-06-20 17:13:21,930\u001b[0m INFO] eval ***** Running evaluation on test-poison *****\n",
      "Evaluating: 100%|██████████| 29/29 [00:00<00:00, 52.05it/s]\n",
      "[\u001b[032m2024-06-20 17:13:22,492\u001b[0m INFO] eval   Num examples = 909\n",
      "[\u001b[032m2024-06-20 17:13:22,494\u001b[0m INFO] eval   accuracy on test-poison: 0.12981298129812982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test-clean': {'accuracy': 0.9011532125205931},\n",
       " 'test-poison': {'accuracy': 0.12981298129812982},\n",
       " 'ppl': nan,\n",
       " 'grammar': nan,\n",
       " 'use': nan}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose SST-2 as the target data\n",
    "target_dataset = load_dataset(name=\"sst-2\")\n",
    "# evaluate attack results\n",
    "badnet_attacker.eval(victim, target_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textGuard39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
