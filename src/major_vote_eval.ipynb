{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-06-23 20:23:32,571 INFO] config PyTorch version 1.11.0+cu113 available.\n"
     ]
    }
   ],
   "source": [
    "import openbackdoor as ob\n",
    "import torch\n",
    "from utils.logger import init_logger\n",
    "from openbackdoor import load_dataset\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fei/NLPLab/miniconda3/envs/textGuard39/lib/python3.9/site-packages/huggingface_hub-0.23.0-py3.9.egg/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir = 'models/sst-2/mix-badnets-0.05'\n",
    "base_model = ob.PLMVictim(model=\"bert\", path=\"bert-base-uncased\")\n",
    "state_dict = torch.load(f'{model_dir}/base_attack/best.ckpt')\n",
    "base_model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[\u001b[032m2024-06-23 21:05:01,853\u001b[0m INFO] badnets_poisoner Initializing BadNet poisoner, triggers are cf mn bb tq\n",
      "[\u001b[032m2024-06-23 21:05:01,902\u001b[0m INFO] __init__ sst-2 dataset loaded, train: 6920, dev: 872, test: 1821\n",
      "[\u001b[032m2024-06-23 21:05:01,909\u001b[0m INFO] eval ***** Running evaluation on test-clean *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 57/57 [00:01<00:00, 49.38it/s]\n",
      "[\u001b[032m2024-06-23 21:05:03,074\u001b[0m INFO] eval   Num examples = 1821\n",
      "[\u001b[032m2024-06-23 21:05:03,078\u001b[0m INFO] eval   accuracy on test-clean: 0.8951125755079626\n",
      "[\u001b[032m2024-06-23 21:05:03,079\u001b[0m INFO] eval ***** Running evaluation on test-poison *****\n",
      "Evaluating: 100%|██████████| 29/29 [00:00<00:00, 50.43it/s]\n",
      "[\u001b[032m2024-06-23 21:05:03,661\u001b[0m INFO] eval   Num examples = 909\n",
      "[\u001b[032m2024-06-23 21:05:03,664\u001b[0m INFO] eval   accuracy on test-poison: 0.900990099009901\n"
     ]
    }
   ],
   "source": [
    "logger = init_logger(log_file=f'{model_dir}/eval_log.txt')\n",
    "\n",
    "base_attacker = ob.Attacker(\n",
    "    poisoner={'name': 'badnets', \"target_label\": 0, \"poison_rate\": 0.05, \"logger\": logger},\n",
    "    train={'name':'base', 'batch_size':32, \"logger\": logger}\n",
    ")   \n",
    "raw_dataset = load_dataset(name='sst-2')\n",
    "res, labels, preds = base_attacker.eval(base_model, raw_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test-clean': {'accuracy': 0.8951125755079626},\n",
       " 'test-poison': {'accuracy': 0.900990099009901},\n",
       " 'ppl': nan,\n",
       " 'grammar': nan,\n",
       " 'use': nan}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[\u001b[032m2024-06-23 21:05:25,056\u001b[0m INFO] eval ***** Running evaluation on test-clean *****\n",
      "Evaluating: 100%|██████████| 57/57 [00:01<00:00, 49.73it/s]\n",
      "[\u001b[032m2024-06-23 21:05:26,207\u001b[0m INFO] eval   Num examples = 1821\n",
      "[\u001b[032m2024-06-23 21:05:26,210\u001b[0m INFO] eval   accuracy on test-clean: 0.8912685337726524\n",
      "[\u001b[032m2024-06-23 21:05:26,211\u001b[0m INFO] eval ***** Running evaluation on test-poison *****\n",
      "Evaluating: 100%|██████████| 29/29 [00:00<00:00, 50.08it/s]\n",
      "[\u001b[032m2024-06-23 21:05:26,798\u001b[0m INFO] eval   Num examples = 909\n",
      "[\u001b[032m2024-06-23 21:05:26,800\u001b[0m INFO] eval   accuracy on test-poison: 0.6017601760176018\n",
      "[\u001b[032m2024-06-23 21:05:27,204\u001b[0m INFO] eval ***** Running evaluation on test-clean *****\n",
      "Evaluating: 100%|██████████| 57/57 [00:01<00:00, 52.58it/s]\n",
      "[\u001b[032m2024-06-23 21:05:28,293\u001b[0m INFO] eval   Num examples = 1821\n",
      "[\u001b[032m2024-06-23 21:05:28,296\u001b[0m INFO] eval   accuracy on test-clean: 0.9028006589785832\n",
      "[\u001b[032m2024-06-23 21:05:28,297\u001b[0m INFO] eval ***** Running evaluation on test-poison *****\n",
      "Evaluating: 100%|██████████| 29/29 [00:00<00:00, 52.30it/s]\n",
      "[\u001b[032m2024-06-23 21:05:28,857\u001b[0m INFO] eval   Num examples = 909\n",
      "[\u001b[032m2024-06-23 21:05:28,860\u001b[0m INFO] eval   accuracy on test-poison: 0.31133113311331134\n",
      "[\u001b[032m2024-06-23 21:05:29,134\u001b[0m INFO] eval ***** Running evaluation on test-clean *****\n",
      "Evaluating: 100%|██████████| 57/57 [00:01<00:00, 52.55it/s]\n",
      "[\u001b[032m2024-06-23 21:05:30,224\u001b[0m INFO] eval   Num examples = 1821\n",
      "[\u001b[032m2024-06-23 21:05:30,227\u001b[0m INFO] eval   accuracy on test-clean: 0.900604063701263\n",
      "[\u001b[032m2024-06-23 21:05:30,228\u001b[0m INFO] eval ***** Running evaluation on test-poison *****\n",
      "Evaluating: 100%|██████████| 29/29 [00:00<00:00, 50.27it/s]\n",
      "[\u001b[032m2024-06-23 21:05:30,811\u001b[0m INFO] eval   Num examples = 909\n",
      "[\u001b[032m2024-06-23 21:05:30,814\u001b[0m INFO] eval   accuracy on test-poison: 0.9922992299229924\n",
      "[\u001b[032m2024-06-23 21:05:31,085\u001b[0m INFO] eval ***** Running evaluation on test-clean *****\n",
      "Evaluating: 100%|██████████| 57/57 [00:01<00:00, 52.08it/s]\n",
      "[\u001b[032m2024-06-23 21:05:32,186\u001b[0m INFO] eval   Num examples = 1821\n",
      "[\u001b[032m2024-06-23 21:05:32,188\u001b[0m INFO] eval   accuracy on test-clean: 0.9104887424492037\n",
      "[\u001b[032m2024-06-23 21:05:32,190\u001b[0m INFO] eval ***** Running evaluation on test-poison *****\n",
      "Evaluating: 100%|██████████| 29/29 [00:00<00:00, 52.76it/s]\n",
      "[\u001b[032m2024-06-23 21:05:32,744\u001b[0m INFO] eval   Num examples = 909\n",
      "[\u001b[032m2024-06-23 21:05:32,747\u001b[0m INFO] eval   accuracy on test-poison: 0.9955995599559956\n",
      "[\u001b[032m2024-06-23 21:05:32,961\u001b[0m INFO] eval ***** Running evaluation on test-clean *****\n",
      "Evaluating: 100%|██████████| 57/57 [00:01<00:00, 53.99it/s]\n",
      "[\u001b[032m2024-06-23 21:05:34,021\u001b[0m INFO] eval   Num examples = 1821\n",
      "[\u001b[032m2024-06-23 21:05:34,023\u001b[0m INFO] eval   accuracy on test-clean: 0.8951125755079626\n",
      "[\u001b[032m2024-06-23 21:05:34,024\u001b[0m INFO] eval ***** Running evaluation on test-poison *****\n",
      "Evaluating: 100%|██████████| 29/29 [00:00<00:00, 54.10it/s]\n",
      "[\u001b[032m2024-06-23 21:05:34,564\u001b[0m INFO] eval   Num examples = 909\n",
      "[\u001b[032m2024-06-23 21:05:34,566\u001b[0m INFO] eval   accuracy on test-poison: 0.88998899889989\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "preds_list = []\n",
    "labels_list = []\n",
    "single_res_list = []\n",
    "defense_setting = 'mix'\n",
    "for style in ['bible', 'shakespeare', 'tweets', 'lyrics', 'poetry']:\n",
    "    style_type = f'{style}_{defense_setting}'\n",
    "    state_dict = torch.load(f'{model_dir}/{style_type}/best.ckpt')\n",
    "    base_model.load_state_dict(state_dict)\n",
    "    results, labels, preds = base_attacker.eval(base_model, raw_dataset)\n",
    "    single_res_list.append(results)\n",
    "    labels_list.append(labels)\n",
    "    preds_list.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1821\n",
      "909\n"
     ]
    }
   ],
   "source": [
    "print(len(preds_list[0]['test-clean']))\n",
    "print(len(preds_list[0]['test-poison']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_indices = sorted(range(len(single_res_list)), key=lambda i: single_res_list[i]['test-poison']['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 4, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "print(sorted_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9022515101592532\n"
     ]
    }
   ],
   "source": [
    "def most_common(lst):\n",
    "    # Returns the most common element in the list\n",
    "    data = Counter(lst)\n",
    "    return data.most_common(1)[0][0]\n",
    "\n",
    "final_results = {\n",
    "    'test-clean': [],\n",
    "    'test-poison': []\n",
    "}\n",
    "preds_list = [preds_list[0], preds_list[1], preds_list[-1]]\n",
    "clean_num_elements = len(preds_list[0]['test-clean'])\n",
    "poison_num_elements = len(preds_list[0]['test-poison'])\n",
    "for i in range(clean_num_elements):\n",
    "    test_clean_votes = [pred['test-clean'][i] for pred in preds_list]\n",
    "    final_results['test-clean'].append(most_common(test_clean_votes))\n",
    "print(accuracy_score(labels['test-clean'], final_results['test-clean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5907590759075908\n"
     ]
    }
   ],
   "source": [
    "for i in range(poison_num_elements):\n",
    "    test_poison_votes = [pred['test-poison'][i] for pred in preds_list]\n",
    "    final_results['test-poison'].append(most_common(test_poison_votes))\n",
    "print(accuracy_score(labels['test-poison'], final_results['test-poison']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textGuard39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
